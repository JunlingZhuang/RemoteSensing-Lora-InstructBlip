{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03ddc3fccc32436c95fa2cbe338e1567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee5b819db5484aa7be19c3f7d8c03dcd",
              "IPY_MODEL_02ab26ea303a414f9fa272a2ab3069ab",
              "IPY_MODEL_ac7eca5c97e340e9bd1cc7b64bf9d643"
            ],
            "layout": "IPY_MODEL_8564619a15ec40f5992f44249e53397d",
            "tabbable": null,
            "tooltip": null
          }
        },
        "ee5b819db5484aa7be19c3f7d8c03dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_995a3a55a1664e6a89c5cbe95e8971bf",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_9b80cf4519a34d72b88e460f9e5a701a",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading‚Äácheckpoint‚Äáshards:‚Äá100%"
          }
        },
        "02ab26ea303a414f9fa272a2ab3069ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c7b8393016874935b0136c294399b2b8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61f2d59cfe4a43b8972799874865d5a0",
            "tabbable": null,
            "tooltip": null,
            "value": 2
          }
        },
        "ac7eca5c97e340e9bd1cc7b64bf9d643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1bf99463642e420d96a7c5dc94fd287f",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_0706b34c2a1d4636992944c090c5b6ad",
            "tabbable": null,
            "tooltip": null,
            "value": "‚Äá2/2‚Äá[00:00&lt;00:00,‚Äá‚Äá3.11it/s]"
          }
        },
        "8564619a15ec40f5992f44249e53397d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "995a3a55a1664e6a89c5cbe95e8971bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b80cf4519a34d72b88e460f9e5a701a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c7b8393016874935b0136c294399b2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f2d59cfe4a43b8972799874865d5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bf99463642e420d96a7c5dc94fd287f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0706b34c2a1d4636992944c090c5b6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SZG5vH5xvPa",
        "outputId": "dc98d64b-abf9-48e3-eb81-ece08c6217c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/RemoteSensing-Lora-InstructBlip\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# ‚úÖ Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ‚úÖ Change to your project directory\n",
        "%cd /content/drive/MyDrive/RemoteSensing-Lora-InstructBlip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Install dependencies from requirements.txt\n",
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "B8ijqbWgyms1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Clean LoRA Training Script for InstructBLIP on RSICap\n",
        "Supports YAML configuration files for flexible training\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import yaml\n",
        "from datetime import datetime\n",
        "# sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'module'))\n",
        "sys.path.insert(0, '/content/drive/MyDrive/RemoteSensing-Lora-InstructBlip/module')\n",
        "\n",
        "from config import Config\n",
        "from data.rsicap_dataset import load_rsicap_data, RSICapDataset, collate_fn\n",
        "from torch.utils.data import DataLoader\n",
        "from models.lora_model import LoRAInstructBLIP\n",
        "from training.trainer import LoRATrainer\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "# Âº∫Âà∂Ê∏ÖÁêÜ\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# # ‰∏≠ÂõΩÈïúÂÉèÊîØÊåÅ\n",
        "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION FILES TO RUN\n",
        "# ============================================================================\n",
        "# Define which config files to run (can be single or multiple)\n",
        "CONFIG_FILES = [\n",
        "    # \"configs/baseline_lora_instructblip.yml\",\n",
        "    # \"configs/high_lr_experiment.yml\",  # Add more configs here\n",
        "    # \"configs/large_batch_experiment.yml\",\n",
        "    # \"configs/grid_search_v4_extreme_rank.yml\",\n",
        "    # \"configs/grid_search_v6_Moderate_Rank_Wider_Batch.yml\",\n",
        "    \"configs/grid_search_v7_Higher_Lora_Wider_Batch.yml\",\n",
        "]\n",
        "\n",
        "# ============================================================================\n",
        "# YAML CONFIG LOADER\n",
        "# ============================================================================\n",
        "def load_yaml_config(config_path):\n",
        "    \"\"\"Load configuration from YAML file\"\"\"\n",
        "    if not os.path.exists(config_path):\n",
        "        raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
        "\n",
        "    with open(config_path, 'r', encoding='utf-8') as f:\n",
        "        yaml_config = yaml.safe_load(f)\n",
        "\n",
        "    print(f\"üìã Loaded config: {yaml_config.get('name', 'unnamed')}\")\n",
        "    if 'description' in yaml_config:\n",
        "        print(f\"üìù Description: {yaml_config['description']}\")\n",
        "\n",
        "    return yaml_config\n",
        "\n",
        "def train_single_config(config_path):\n",
        "    \"\"\"Train with a single YAML configuration\"\"\"\n",
        "\n",
        "    # Load YAML configuration\n",
        "    yaml_config = load_yaml_config(config_path)\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"üöÄ LoRA Training - InstructBLIP on RSICap\")\n",
        "    print(f\"üìã Config: {yaml_config.get('name', 'unnamed')}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Create config object\n",
        "    config = Config()\n",
        "\n",
        "    # Apply YAML config (skip metadata fields)\n",
        "    metadata_fields = {'name', 'description'}\n",
        "    for key, value in yaml_config.items():\n",
        "        if key not in metadata_fields:\n",
        "            setattr(config, key, value)\n",
        "\n",
        "    # Create output directory using config name\n",
        "    config_name = yaml_config.get('name', 'unnamed_config')\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    config.save_dir = f\"checkpoints/{config_name}_{timestamp}\"\n",
        "    os.makedirs(config.save_dir, exist_ok=True)\n",
        "\n",
        "    # Êï∞ÊçÆË∑ØÂæÑÂ∑≤Âú® config.py ‰∏≠Ê≠£Á°ÆËÆæÁΩÆ\n",
        "\n",
        "    # ÊòæÁ§∫ÈÖçÁΩÆ\n",
        "    print(f\"üìã Training Configuration:\")\n",
        "    print(f\"  LoRA rank (r): {config.lora_r}\")\n",
        "    print(f\"  LoRA alpha: {config.lora_alpha}\")\n",
        "    print(f\"  Learning rate: {config.learning_rate}\")\n",
        "    print(f\"  Epochs: {config.num_epochs}\")\n",
        "    print(f\"  Batch size: {config.batch_size}\")\n",
        "    print(f\"  Max samples: {config.max_samples}\")\n",
        "    print(f\"  Save dir: {config.save_dir}\")\n",
        "    print()\n",
        "\n",
        "    # Âä†ËΩΩÁªÑ‰ª∂\n",
        "    print(\"Loading LoRA model...\")\n",
        "    model = LoRAInstructBLIP(config)\n",
        "    print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "    print(\"Loading dataset...\")\n",
        "    train_loader, val_loader, processor = load_rsicap_data(config)\n",
        "    print(\"‚úÖ Dataset loaded successfully!\")\n",
        "\n",
        "    # ÈôêÂà∂Êï∞ÊçÆÈáè\n",
        "    if config.max_samples:\n",
        "        print(f\"üî¢ Limiting training to {config.max_samples} samples\")\n",
        "        limited_train_data = list(train_loader.dataset.data)[:config.max_samples]\n",
        "        limited_train_dataset = RSICapDataset(\n",
        "            limited_train_data,\n",
        "            train_loader.dataset.images_dir,\n",
        "            train_loader.dataset.processor,\n",
        "            'train'\n",
        "        )\n",
        "        train_loader = DataLoader(\n",
        "            limited_train_dataset,\n",
        "            batch_size=config.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            pin_memory=True,\n",
        "            collate_fn=collate_fn\n",
        "        )\n",
        "        print(f\"‚úÖ Limited to {len(train_loader)} batches per epoch\")\n",
        "\n",
        "    # ÂàõÂª∫ËÆ≠ÁªÉÂô®\n",
        "    print(\"Creating trainer...\")\n",
        "    trainer = LoRATrainer(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        config=config\n",
        "    )\n",
        "    print(\"‚úÖ Trainer created successfully!\")\n",
        "\n",
        "    # È™åËØÅ LoRA ÈÖçÁΩÆ\n",
        "    model.verify_lora_training()\n",
        "\n",
        "    # ÂºÄÂßãËÆ≠ÁªÉ\n",
        "    print(\"\\nüöÄ Starting LoRA training...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    latest_checkpoint_path = None\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch + 1}/{config.num_epochs} ---\")\n",
        "\n",
        "        # ËÆ≠ÁªÉ\n",
        "        train_loss, epoch_time = trainer.train_epoch(epoch)\n",
        "\n",
        "        # È™åËØÅ\n",
        "        val_loss = trainer.validate(epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}: Train={train_loss:.4f}, Val={val_loss:.4f}, Time={epoch_time:.1f}s\")\n",
        "\n",
        "        # ‰øùÂ≠òÊØè‰∏™epochÁöÑÂéÜÂè≤ËÆ∞ÂΩï\n",
        "        epoch_summary = {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"epoch_time\": epoch_time,\n",
        "            \"learning_rate\": trainer.optimizer.param_groups[0]['lr'] if hasattr(trainer, 'optimizer') else None,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        # ‰øùÂ≠òÂçï‰∏™epochÊÄªÁªì\n",
        "        epoch_file = os.path.join(config.save_dir, f\"epoch_{epoch+1}_summary.json\")\n",
        "        with open(epoch_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(epoch_summary, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        # ‰øùÂ≠òÁ¥ØÁßØÂéÜÂè≤\n",
        "        history_file = os.path.join(config.save_dir, \"training_history.json\")\n",
        "        if os.path.exists(history_file):\n",
        "            with open(history_file, 'r', encoding='utf-8') as f:\n",
        "                history = json.load(f)\n",
        "        else:\n",
        "            history = {\"epochs\": []}\n",
        "\n",
        "        history[\"epochs\"].append(epoch_summary)\n",
        "        history[\"config\"] = yaml_config\n",
        "        history[\"last_updated\"] = datetime.now().isoformat()\n",
        "\n",
        "        with open(history_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(history, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(f\"üìä Epoch {epoch + 1} history saved\")\n",
        "\n",
        "        # ‰øùÂ≠òÊ£ÄÊü•ÁÇπ\n",
        "        if (epoch + 1) % 2 == 0 or epoch == config.num_epochs - 1:\n",
        "            latest_checkpoint_path = os.path.join(config.save_dir, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
        "            trainer.save_checkpoint(latest_checkpoint_path, epoch, train_loss, val_loss)\n",
        "            print(f\"üíæ Checkpoint saved: {latest_checkpoint_path}\")\n",
        "\n",
        "    # ‰øùÂ≠òËÆ≠ÁªÉÊÄªÁªìÂíåÁîüÊàêÂèØËßÜÂåñ\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üéâ Training Completed!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Ë∞ÉÁî®trainerÁöÑËØ¶ÁªÜ‰øùÂ≠òÂäüËÉΩÔºàÂåÖÂê´ÂèØËßÜÂåñÔºâ\n",
        "    if hasattr(trainer, 'save_training_summary'):\n",
        "        detailed_summary_path = trainer.save_training_summary()\n",
        "        print(f\"üìä Detailed training summary with plots saved: {detailed_summary_path}\")\n",
        "    else:\n",
        "        # Â¶ÇÊûútrainerÊ≤°ÊúâËøô‰∏™ÊñπÊ≥ïÔºåË∞ÉÁî®plot_losses\n",
        "        if hasattr(trainer, 'plot_losses'):\n",
        "            trainer.plot_losses()\n",
        "            print(f\"üìà Training curves saved to: {config.save_dir}/training_curves.png\")\n",
        "\n",
        "    # ‰øùÂ≠òÂü∫Êú¨ÊÄªÁªì\n",
        "    summary = {\n",
        "        \"training_completed\": datetime.now().isoformat(),\n",
        "        \"config\": yaml_config,\n",
        "        \"final_losses\": {\n",
        "            \"train_loss\": trainer.train_losses[-1] if trainer.train_losses else None,\n",
        "            \"val_loss\": trainer.val_losses[-1] if trainer.val_losses else None\n",
        "        },\n",
        "        \"best_val_loss\": min(trainer.val_losses) if trainer.val_losses else None,\n",
        "        \"total_epochs\": len(trainer.train_losses),\n",
        "        \"total_training_time\": sum(trainer.epoch_times) if hasattr(trainer, 'epoch_times') else None,\n",
        "        \"checkpoints_dir\": config.save_dir\n",
        "    }\n",
        "\n",
        "    summary_path = os.path.join(config.save_dir, \"training_summary.json\")\n",
        "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"üìÑ Basic training summary saved: {summary_path}\")\n",
        "    print(f\"üíæ Latest checkpoint: {latest_checkpoint_path}\")\n",
        "    print(f\"üìÅ All files saved to: {config.save_dir}\")\n",
        "    print(\"\\n‚úÖ All done!\")\n",
        "    return latest_checkpoint_path\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run training with multiple configurations\"\"\"\n",
        "\n",
        "    print(\"üöÄ Starting LoRA Training Pipeline\")\n",
        "    print(f\"üìÅ Found {len(CONFIG_FILES)} configuration(s) to run\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, config_path in enumerate(CONFIG_FILES, 1):\n",
        "        print(f\"\\nüîÑ Running configuration {i}/{len(CONFIG_FILES)}: {config_path}\")\n",
        "\n",
        "        try:\n",
        "            checkpoint_path = train_single_config(config_path)\n",
        "            results.append({\n",
        "                \"config_path\": config_path,\n",
        "                \"status\": \"success\",\n",
        "                \"checkpoint\": checkpoint_path\n",
        "            })\n",
        "            print(f\"‚úÖ Configuration {i} completed successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Configuration {i} failed: {e}\")\n",
        "            results.append({\n",
        "                \"config_path\": config_path,\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "\n",
        "    # Print final summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üéâ Training Pipeline Completed!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    successful = [r for r in results if r[\"status\"] == \"success\"]\n",
        "    failed = [r for r in results if r[\"status\"] == \"failed\"]\n",
        "\n",
        "    print(f\"‚úÖ Successful: {len(successful)}\")\n",
        "    print(f\"‚ùå Failed: {len(failed)}\")\n",
        "\n",
        "    if successful:\n",
        "        print(\"\\nüìä Successful Runs:\")\n",
        "        for result in successful:\n",
        "            config_name = os.path.basename(result[\"config_path\"])\n",
        "            print(f\"  - {config_name} ‚Üí {result['checkpoint']}\")\n",
        "\n",
        "    if failed:\n",
        "        print(\"\\nüí• Failed Runs:\")\n",
        "        for result in failed:\n",
        "            config_name = os.path.basename(result[\"config_path\"])\n",
        "            print(f\"  - {config_name}: {result['error']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "03ddc3fccc32436c95fa2cbe338e1567",
            "ee5b819db5484aa7be19c3f7d8c03dcd",
            "02ab26ea303a414f9fa272a2ab3069ab",
            "ac7eca5c97e340e9bd1cc7b64bf9d643",
            "8564619a15ec40f5992f44249e53397d",
            "995a3a55a1664e6a89c5cbe95e8971bf",
            "9b80cf4519a34d72b88e460f9e5a701a",
            "c7b8393016874935b0136c294399b2b8",
            "61f2d59cfe4a43b8972799874865d5a0",
            "1bf99463642e420d96a7c5dc94fd287f",
            "0706b34c2a1d4636992944c090c5b6ad"
          ]
        },
        "id": "sYoBHMImzZG_",
        "outputId": "f27f4d25-99c4-4d5a-a795-734a39cda9a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting LoRA Training Pipeline\n",
            "üìÅ Found 1 configuration(s) to run\n",
            "============================================================\n",
            "\n",
            "üîÑ Running configuration 1/1: configs/grid_search_v7_Higher_Lora_Wider_Batch.yml\n",
            "üìã Loaded config: grid_search_v7_Higher_Lora_Wider_Batch\n",
            "üìù Description: Grid search configuration for higher LoRA and wider batch\n",
            "============================================================\n",
            "üöÄ LoRA Training - InstructBLIP on RSICap\n",
            "üìã Config: grid_search_v7_Higher_Lora_Wider_Batch\n",
            "============================================================\n",
            "üìã Training Configuration:\n",
            "  LoRA rank (r): 24\n",
            "  LoRA alpha: 48\n",
            "  Learning rate: 0.0003\n",
            "  Epochs: 8\n",
            "  Batch size: 15\n",
            "  Max samples: 2068\n",
            "  Save dir: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058\n",
            "\n",
            "Loading LoRA model...\n",
            "Loading base model: Salesforce/instructblip-flan-t5-xl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03ddc3fccc32436c95fa2cbe338e1567"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying LoRA to Q-Former only...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 7,262,208 || all params: 4,030,231,296 || trainable%: 0.1802\n",
            "‚úÖ Model loaded successfully!\n",
            "Loading dataset...\n",
            "Loading RSICap data from data/rsgpt_dataset/RSICap/captions.json\n",
            "Loaded 2585 samples\n",
            "Split: 2068 train, 517 validation\n",
            "‚úÖ Dataset loaded successfully!\n",
            "üî¢ Limiting training to 2068 samples\n",
            "‚úÖ Limited to 138 batches per epoch\n",
            "Creating trainer...\n",
            "‚úÖ Trainer created successfully!\n",
            "\n",
            "============================================================\n",
            "LoRA Training Verification\n",
            "============================================================\n",
            "Total parameters: 4,030,231,296\n",
            "Trainable parameters: 7,262,208\n",
            "Trainable percentage: 0.1802%\n",
            "LoRA parameters found: 240\n",
            "\n",
            "LoRA Parameters Details:\n",
            "  base_model.model.qformer.encoder.layer.0.attention.attention.query.lora_A.default.weight: torch.Size([24, 768]), mean=0.000135, std=0.020943\n",
            "  base_model.model.qformer.encoder.layer.0.attention.attention.query.lora_B.default.weight: torch.Size([768, 24]), mean=0.000000, std=0.000000\n",
            "  base_model.model.qformer.encoder.layer.0.attention.attention.key.lora_A.default.weight: torch.Size([24, 768]), mean=-0.000052, std=0.020939\n",
            "  base_model.model.qformer.encoder.layer.0.attention.attention.key.lora_B.default.weight: torch.Size([768, 24]), mean=0.000000, std=0.000000\n",
            "  base_model.model.qformer.encoder.layer.0.attention.attention.value.lora_A.default.weight: torch.Size([24, 768]), mean=0.000314, std=0.020810\n",
            "  ... and 235 more LoRA parameters\n",
            "\n",
            "Q-Former Analysis:\n",
            "  Total Q-Former parameters: 192,922,368\n",
            "  Q-Former LoRA parameters: 7,262,208\n",
            "‚úÖ Q-Former LoRA is correctly configured!\n",
            "============================================================\n",
            "\n",
            "üöÄ Starting LoRA training...\n",
            "============================================================\n",
            "\n",
            "--- Epoch 1/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/8:   0%|          | 0/138 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3951: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "Epoch 1/8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138/138 [04:55<00:00,  2.14s/it, Loss=1.7224, Avg=1.8852, LR=2.8e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 1 completed in 295.42s\n",
            "üìä Average training loss: 1.8852\n",
            "üî¢ Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Validation loss: 1.5452\n",
            "üî¢ Processed 35/35 valid validation batches\n",
            "Epoch 1: Train=1.8852, Val=1.5452, Time=295.4s\n",
            "üìä Epoch 1 history saved\n",
            "\n",
            "--- Epoch 2/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138/138 [04:54<00:00,  2.14s/it, Loss=1.6797, Avg=1.6454, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 2 completed in 294.67s\n",
            "üìä Average training loss: 1.6454\n",
            "üî¢ Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Validation loss: 1.5053\n",
            "üî¢ Processed 35/35 valid validation batches\n",
            "Epoch 2: Train=1.6454, Val=1.5053, Time=294.7s\n",
            "üìä Epoch 2 history saved\n",
            "Model saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_2.pth\n",
            "Checkpoint saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_2.pth\n",
            "üíæ Checkpoint saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_2.pth\n",
            "\n",
            "--- Epoch 3/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138/138 [04:54<00:00,  2.13s/it, Loss=1.3979, Avg=1.6001, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 3 completed in 294.47s\n",
            "üìä Average training loss: 1.6001\n",
            "üî¢ Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Validation loss: 1.4704\n",
            "üî¢ Processed 35/35 valid validation batches\n",
            "Epoch 3: Train=1.6001, Val=1.4704, Time=294.5s\n",
            "üìä Epoch 3 history saved\n",
            "\n",
            "--- Epoch 4/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138/138 [04:54<00:00,  2.14s/it, Loss=1.5805, Avg=1.5805, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 4 completed in 294.77s\n",
            "üìä Average training loss: 1.5805\n",
            "üî¢ Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Validation loss: 1.4425\n",
            "üî¢ Processed 35/35 valid validation batches\n",
            "Epoch 4: Train=1.5805, Val=1.4425, Time=294.8s\n",
            "üìä Epoch 4 history saved\n",
            "Model saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_4.pth\n",
            "Checkpoint saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_4.pth\n",
            "üíæ Checkpoint saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_4.pth\n",
            "\n",
            "--- Epoch 5/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138/138 [04:54<00:00,  2.14s/it, Loss=1.4594, Avg=1.5574, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 5 completed in 294.78s\n",
            "üìä Average training loss: 1.5574\n",
            "üî¢ Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Validation loss: 1.4378\n",
            "üî¢ Processed 35/35 valid validation batches\n",
            "Epoch 5: Train=1.5574, Val=1.4378, Time=294.8s\n",
            "üìä Epoch 5 history saved\n",
            "\n",
            "--- Epoch 6/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138/138 [04:54<00:00,  2.13s/it, Loss=1.4108, Avg=1.5413, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 6 completed in 294.20s\n",
            "üìä Average training loss: 1.5413\n",
            "üî¢ Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Validation loss: 1.4305\n",
            "üî¢ Processed 35/35 valid validation batches\n",
            "Epoch 6: Train=1.5413, Val=1.4305, Time=294.2s\n",
            "üìä Epoch 6 history saved\n",
            "Model saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_6.pth\n",
            "Checkpoint saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_6.pth\n",
            "üíæ Checkpoint saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_6.pth\n",
            "\n",
            "--- Epoch 7/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138/138 [04:54<00:00,  2.13s/it, Loss=1.6078, Avg=1.5282, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 7 completed in 294.62s\n",
            "üìä Average training loss: 1.5282\n",
            "üî¢ Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Validation loss: 1.4175\n",
            "üî¢ Processed 35/35 valid validation batches\n",
            "Epoch 7: Train=1.5282, Val=1.4175, Time=294.6s\n",
            "üìä Epoch 7 history saved\n",
            "\n",
            "--- Epoch 8/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/8: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 138/138 [04:54<00:00,  2.13s/it, Loss=1.7005, Avg=1.5184, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Epoch 8 completed in 294.45s\n",
            "üìä Average training loss: 1.5184\n",
            "üî¢ Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìà Validation loss: 1.4190\n",
            "üî¢ Processed 35/35 valid validation batches\n",
            "Epoch 8: Train=1.5184, Val=1.4190, Time=294.5s\n",
            "üìä Epoch 8 history saved\n",
            "Model saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_8.pth\n",
            "Checkpoint saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_8.pth\n",
            "üíæ Checkpoint saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_8.pth\n",
            "\n",
            "============================================================\n",
            "üéâ Training Completed!\n",
            "============================================================\n",
            "üìä Detailed training summary saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/training_summary_detailed.json\n",
            "üìà Training curves saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/training_curves.png\n",
            "üìä Detailed training summary with plots saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/training_summary_detailed.json\n",
            "üìÑ Basic training summary saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/training_summary.json\n",
            "üíæ Latest checkpoint: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_8.pth\n",
            "üìÅ All files saved to: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058\n",
            "\n",
            "‚úÖ All done!\n",
            "‚úÖ Configuration 1 completed successfully!\n",
            "\n",
            "============================================================\n",
            "üéâ Training Pipeline Completed!\n",
            "============================================================\n",
            "‚úÖ Successful: 1\n",
            "‚ùå Failed: 0\n",
            "\n",
            "üìä Successful Runs:\n",
            "  - grid_search_v7_Higher_Lora_Wider_Batch.yml ‚Üí checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_8.pth\n"
          ]
        }
      ]
    }
  ]
}