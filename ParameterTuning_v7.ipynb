{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03ddc3fccc32436c95fa2cbe338e1567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ee5b819db5484aa7be19c3f7d8c03dcd",
              "IPY_MODEL_02ab26ea303a414f9fa272a2ab3069ab",
              "IPY_MODEL_ac7eca5c97e340e9bd1cc7b64bf9d643"
            ],
            "layout": "IPY_MODEL_8564619a15ec40f5992f44249e53397d",
            "tabbable": null,
            "tooltip": null
          }
        },
        "ee5b819db5484aa7be19c3f7d8c03dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_995a3a55a1664e6a89c5cbe95e8971bf",
            "placeholder": "​",
            "style": "IPY_MODEL_9b80cf4519a34d72b88e460f9e5a701a",
            "tabbable": null,
            "tooltip": null,
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "02ab26ea303a414f9fa272a2ab3069ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_c7b8393016874935b0136c294399b2b8",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61f2d59cfe4a43b8972799874865d5a0",
            "tabbable": null,
            "tooltip": null,
            "value": 2
          }
        },
        "ac7eca5c97e340e9bd1cc7b64bf9d643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "2.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "2.0.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_allow_html": false,
            "layout": "IPY_MODEL_1bf99463642e420d96a7c5dc94fd287f",
            "placeholder": "​",
            "style": "IPY_MODEL_0706b34c2a1d4636992944c090c5b6ad",
            "tabbable": null,
            "tooltip": null,
            "value": " 2/2 [00:00&lt;00:00,  3.11it/s]"
          }
        },
        "8564619a15ec40f5992f44249e53397d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "995a3a55a1664e6a89c5cbe95e8971bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b80cf4519a34d72b88e460f9e5a701a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        },
        "c7b8393016874935b0136c294399b2b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61f2d59cfe4a43b8972799874865d5a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1bf99463642e420d96a7c5dc94fd287f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "2.0.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border_bottom": null,
            "border_left": null,
            "border_right": null,
            "border_top": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0706b34c2a1d4636992944c090c5b6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLStyleModel",
          "model_module_version": "2.0.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "2.0.0",
            "_model_name": "HTMLStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "2.0.0",
            "_view_name": "StyleView",
            "background": null,
            "description_width": "",
            "font_size": null,
            "text_color": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SZG5vH5xvPa",
        "outputId": "dc98d64b-abf9-48e3-eb81-ece08c6217c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/RemoteSensing-Lora-InstructBlip\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "\n",
        "# ✅ Mount your Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ✅ Change to your project directory\n",
        "%cd /content/drive/MyDrive/RemoteSensing-Lora-InstructBlip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Install dependencies from requirements.txt\n",
        "# !pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "B8ijqbWgyms1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Clean LoRA Training Script for InstructBLIP on RSICap\n",
        "Supports YAML configuration files for flexible training\n",
        "\"\"\"\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import yaml\n",
        "from datetime import datetime\n",
        "# sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'module'))\n",
        "sys.path.insert(0, '/content/drive/MyDrive/RemoteSensing-Lora-InstructBlip/module')\n",
        "\n",
        "from config import Config\n",
        "from data.rsicap_dataset import load_rsicap_data, RSICapDataset, collate_fn\n",
        "from torch.utils.data import DataLoader\n",
        "from models.lora_model import LoRAInstructBLIP\n",
        "from training.trainer import LoRATrainer\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "# 强制清理\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# # 中国镜像支持\n",
        "# os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'\n",
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION FILES TO RUN\n",
        "# ============================================================================\n",
        "# Define which config files to run (can be single or multiple)\n",
        "CONFIG_FILES = [\n",
        "    # \"configs/baseline_lora_instructblip.yml\",\n",
        "    # \"configs/high_lr_experiment.yml\",  # Add more configs here\n",
        "    # \"configs/large_batch_experiment.yml\",\n",
        "    # \"configs/grid_search_v4_extreme_rank.yml\",\n",
        "    # \"configs/grid_search_v6_Moderate_Rank_Wider_Batch.yml\",\n",
        "    \"configs/grid_search_v7_Higher_Lora_Wider_Batch.yml\",\n",
        "]\n",
        "\n",
        "# ============================================================================\n",
        "# YAML CONFIG LOADER\n",
        "# ============================================================================\n",
        "def load_yaml_config(config_path):\n",
        "    \"\"\"Load configuration from YAML file\"\"\"\n",
        "    if not os.path.exists(config_path):\n",
        "        raise FileNotFoundError(f\"Config file not found: {config_path}\")\n",
        "\n",
        "    with open(config_path, 'r', encoding='utf-8') as f:\n",
        "        yaml_config = yaml.safe_load(f)\n",
        "\n",
        "    print(f\"📋 Loaded config: {yaml_config.get('name', 'unnamed')}\")\n",
        "    if 'description' in yaml_config:\n",
        "        print(f\"📝 Description: {yaml_config['description']}\")\n",
        "\n",
        "    return yaml_config\n",
        "\n",
        "def train_single_config(config_path):\n",
        "    \"\"\"Train with a single YAML configuration\"\"\"\n",
        "\n",
        "    # Load YAML configuration\n",
        "    yaml_config = load_yaml_config(config_path)\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"🚀 LoRA Training - InstructBLIP on RSICap\")\n",
        "    print(f\"📋 Config: {yaml_config.get('name', 'unnamed')}\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Create config object\n",
        "    config = Config()\n",
        "\n",
        "    # Apply YAML config (skip metadata fields)\n",
        "    metadata_fields = {'name', 'description'}\n",
        "    for key, value in yaml_config.items():\n",
        "        if key not in metadata_fields:\n",
        "            setattr(config, key, value)\n",
        "\n",
        "    # Create output directory using config name\n",
        "    config_name = yaml_config.get('name', 'unnamed_config')\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    config.save_dir = f\"checkpoints/{config_name}_{timestamp}\"\n",
        "    os.makedirs(config.save_dir, exist_ok=True)\n",
        "\n",
        "    # 数据路径已在 config.py 中正确设置\n",
        "\n",
        "    # 显示配置\n",
        "    print(f\"📋 Training Configuration:\")\n",
        "    print(f\"  LoRA rank (r): {config.lora_r}\")\n",
        "    print(f\"  LoRA alpha: {config.lora_alpha}\")\n",
        "    print(f\"  Learning rate: {config.learning_rate}\")\n",
        "    print(f\"  Epochs: {config.num_epochs}\")\n",
        "    print(f\"  Batch size: {config.batch_size}\")\n",
        "    print(f\"  Max samples: {config.max_samples}\")\n",
        "    print(f\"  Save dir: {config.save_dir}\")\n",
        "    print()\n",
        "\n",
        "    # 加载组件\n",
        "    print(\"Loading LoRA model...\")\n",
        "    model = LoRAInstructBLIP(config)\n",
        "    print(\"✅ Model loaded successfully!\")\n",
        "\n",
        "    print(\"Loading dataset...\")\n",
        "    train_loader, val_loader, processor = load_rsicap_data(config)\n",
        "    print(\"✅ Dataset loaded successfully!\")\n",
        "\n",
        "    # 限制数据量\n",
        "    if config.max_samples:\n",
        "        print(f\"🔢 Limiting training to {config.max_samples} samples\")\n",
        "        limited_train_data = list(train_loader.dataset.data)[:config.max_samples]\n",
        "        limited_train_dataset = RSICapDataset(\n",
        "            limited_train_data,\n",
        "            train_loader.dataset.images_dir,\n",
        "            train_loader.dataset.processor,\n",
        "            'train'\n",
        "        )\n",
        "        train_loader = DataLoader(\n",
        "            limited_train_dataset,\n",
        "            batch_size=config.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=0,\n",
        "            pin_memory=True,\n",
        "            collate_fn=collate_fn\n",
        "        )\n",
        "        print(f\"✅ Limited to {len(train_loader)} batches per epoch\")\n",
        "\n",
        "    # 创建训练器\n",
        "    print(\"Creating trainer...\")\n",
        "    trainer = LoRATrainer(\n",
        "        model=model,\n",
        "        train_loader=train_loader,\n",
        "        val_loader=val_loader,\n",
        "        config=config\n",
        "    )\n",
        "    print(\"✅ Trainer created successfully!\")\n",
        "\n",
        "    # 验证 LoRA 配置\n",
        "    model.verify_lora_training()\n",
        "\n",
        "    # 开始训练\n",
        "    print(\"\\n🚀 Starting LoRA training...\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    latest_checkpoint_path = None\n",
        "\n",
        "    for epoch in range(config.num_epochs):\n",
        "        print(f\"\\n--- Epoch {epoch + 1}/{config.num_epochs} ---\")\n",
        "\n",
        "        # 训练\n",
        "        train_loss, epoch_time = trainer.train_epoch(epoch)\n",
        "\n",
        "        # 验证\n",
        "        val_loss = trainer.validate(epoch)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}: Train={train_loss:.4f}, Val={val_loss:.4f}, Time={epoch_time:.1f}s\")\n",
        "\n",
        "        # 保存每个epoch的历史记录\n",
        "        epoch_summary = {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"epoch_time\": epoch_time,\n",
        "            \"learning_rate\": trainer.optimizer.param_groups[0]['lr'] if hasattr(trainer, 'optimizer') else None,\n",
        "            \"timestamp\": datetime.now().isoformat()\n",
        "        }\n",
        "\n",
        "        # 保存单个epoch总结\n",
        "        epoch_file = os.path.join(config.save_dir, f\"epoch_{epoch+1}_summary.json\")\n",
        "        with open(epoch_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(epoch_summary, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        # 保存累积历史\n",
        "        history_file = os.path.join(config.save_dir, \"training_history.json\")\n",
        "        if os.path.exists(history_file):\n",
        "            with open(history_file, 'r', encoding='utf-8') as f:\n",
        "                history = json.load(f)\n",
        "        else:\n",
        "            history = {\"epochs\": []}\n",
        "\n",
        "        history[\"epochs\"].append(epoch_summary)\n",
        "        history[\"config\"] = yaml_config\n",
        "        history[\"last_updated\"] = datetime.now().isoformat()\n",
        "\n",
        "        with open(history_file, 'w', encoding='utf-8') as f:\n",
        "            json.dump(history, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "        print(f\"📊 Epoch {epoch + 1} history saved\")\n",
        "\n",
        "        # 保存检查点\n",
        "        if (epoch + 1) % 2 == 0 or epoch == config.num_epochs - 1:\n",
        "            latest_checkpoint_path = os.path.join(config.save_dir, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
        "            trainer.save_checkpoint(latest_checkpoint_path, epoch, train_loss, val_loss)\n",
        "            print(f\"💾 Checkpoint saved: {latest_checkpoint_path}\")\n",
        "\n",
        "    # 保存训练总结和生成可视化\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🎉 Training Completed!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # 调用trainer的详细保存功能（包含可视化）\n",
        "    if hasattr(trainer, 'save_training_summary'):\n",
        "        detailed_summary_path = trainer.save_training_summary()\n",
        "        print(f\"📊 Detailed training summary with plots saved: {detailed_summary_path}\")\n",
        "    else:\n",
        "        # 如果trainer没有这个方法，调用plot_losses\n",
        "        if hasattr(trainer, 'plot_losses'):\n",
        "            trainer.plot_losses()\n",
        "            print(f\"📈 Training curves saved to: {config.save_dir}/training_curves.png\")\n",
        "\n",
        "    # 保存基本总结\n",
        "    summary = {\n",
        "        \"training_completed\": datetime.now().isoformat(),\n",
        "        \"config\": yaml_config,\n",
        "        \"final_losses\": {\n",
        "            \"train_loss\": trainer.train_losses[-1] if trainer.train_losses else None,\n",
        "            \"val_loss\": trainer.val_losses[-1] if trainer.val_losses else None\n",
        "        },\n",
        "        \"best_val_loss\": min(trainer.val_losses) if trainer.val_losses else None,\n",
        "        \"total_epochs\": len(trainer.train_losses),\n",
        "        \"total_training_time\": sum(trainer.epoch_times) if hasattr(trainer, 'epoch_times') else None,\n",
        "        \"checkpoints_dir\": config.save_dir\n",
        "    }\n",
        "\n",
        "    summary_path = os.path.join(config.save_dir, \"training_summary.json\")\n",
        "    with open(summary_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(summary, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "    print(f\"📄 Basic training summary saved: {summary_path}\")\n",
        "    print(f\"💾 Latest checkpoint: {latest_checkpoint_path}\")\n",
        "    print(f\"📁 All files saved to: {config.save_dir}\")\n",
        "    print(\"\\n✅ All done!\")\n",
        "    return latest_checkpoint_path\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run training with multiple configurations\"\"\"\n",
        "\n",
        "    print(\"🚀 Starting LoRA Training Pipeline\")\n",
        "    print(f\"📁 Found {len(CONFIG_FILES)} configuration(s) to run\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, config_path in enumerate(CONFIG_FILES, 1):\n",
        "        print(f\"\\n🔄 Running configuration {i}/{len(CONFIG_FILES)}: {config_path}\")\n",
        "\n",
        "        try:\n",
        "            checkpoint_path = train_single_config(config_path)\n",
        "            results.append({\n",
        "                \"config_path\": config_path,\n",
        "                \"status\": \"success\",\n",
        "                \"checkpoint\": checkpoint_path\n",
        "            })\n",
        "            print(f\"✅ Configuration {i} completed successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"❌ Configuration {i} failed: {e}\")\n",
        "            results.append({\n",
        "                \"config_path\": config_path,\n",
        "                \"status\": \"failed\",\n",
        "                \"error\": str(e)\n",
        "            })\n",
        "\n",
        "    # Print final summary\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"🎉 Training Pipeline Completed!\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    successful = [r for r in results if r[\"status\"] == \"success\"]\n",
        "    failed = [r for r in results if r[\"status\"] == \"failed\"]\n",
        "\n",
        "    print(f\"✅ Successful: {len(successful)}\")\n",
        "    print(f\"❌ Failed: {len(failed)}\")\n",
        "\n",
        "    if successful:\n",
        "        print(\"\\n📊 Successful Runs:\")\n",
        "        for result in successful:\n",
        "            config_name = os.path.basename(result[\"config_path\"])\n",
        "            print(f\"  - {config_name} → {result['checkpoint']}\")\n",
        "\n",
        "    if failed:\n",
        "        print(\"\\n💥 Failed Runs:\")\n",
        "        for result in failed:\n",
        "            config_name = os.path.basename(result[\"config_path\"])\n",
        "            print(f\"  - {config_name}: {result['error']}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "03ddc3fccc32436c95fa2cbe338e1567",
            "ee5b819db5484aa7be19c3f7d8c03dcd",
            "02ab26ea303a414f9fa272a2ab3069ab",
            "ac7eca5c97e340e9bd1cc7b64bf9d643",
            "8564619a15ec40f5992f44249e53397d",
            "995a3a55a1664e6a89c5cbe95e8971bf",
            "9b80cf4519a34d72b88e460f9e5a701a",
            "c7b8393016874935b0136c294399b2b8",
            "61f2d59cfe4a43b8972799874865d5a0",
            "1bf99463642e420d96a7c5dc94fd287f",
            "0706b34c2a1d4636992944c090c5b6ad"
          ]
        },
        "id": "sYoBHMImzZG_",
        "outputId": "f27f4d25-99c4-4d5a-a795-734a39cda9a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Starting LoRA Training Pipeline\n",
            "📁 Found 1 configuration(s) to run\n",
            "============================================================\n",
            "\n",
            "🔄 Running configuration 1/1: configs/grid_search_v7_Higher_Lora_Wider_Batch.yml\n",
            "📋 Loaded config: grid_search_v7_Higher_Lora_Wider_Batch\n",
            "📝 Description: Grid search configuration for higher LoRA and wider batch\n",
            "============================================================\n",
            "🚀 LoRA Training - InstructBLIP on RSICap\n",
            "📋 Config: grid_search_v7_Higher_Lora_Wider_Batch\n",
            "============================================================\n",
            "📋 Training Configuration:\n",
            "  LoRA rank (r): 24\n",
            "  LoRA alpha: 48\n",
            "  Learning rate: 0.0003\n",
            "  Epochs: 8\n",
            "  Batch size: 15\n",
            "  Max samples: 2068\n",
            "  Save dir: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058\n",
            "\n",
            "Loading LoRA model...\n",
            "Loading base model: Salesforce/instructblip-flan-t5-xl\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "03ddc3fccc32436c95fa2cbe338e1567"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Applying LoRA to Q-Former only...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 7,262,208 || all params: 4,030,231,296 || trainable%: 0.1802\n",
            "✅ Model loaded successfully!\n",
            "Loading dataset...\n",
            "Loading RSICap data from data/rsgpt_dataset/RSICap/captions.json\n",
            "Loaded 2585 samples\n",
            "Split: 2068 train, 517 validation\n",
            "✅ Dataset loaded successfully!\n",
            "🔢 Limiting training to 2068 samples\n",
            "✅ Limited to 138 batches per epoch\n",
            "Creating trainer...\n",
            "✅ Trainer created successfully!\n",
            "\n",
            "============================================================\n",
            "LoRA Training Verification\n",
            "============================================================\n",
            "Total parameters: 4,030,231,296\n",
            "Trainable parameters: 7,262,208\n",
            "Trainable percentage: 0.1802%\n",
            "LoRA parameters found: 240\n",
            "\n",
            "LoRA Parameters Details:\n",
            "  base_model.model.qformer.encoder.layer.0.attention.attention.query.lora_A.default.weight: torch.Size([24, 768]), mean=0.000135, std=0.020943\n",
            "  base_model.model.qformer.encoder.layer.0.attention.attention.query.lora_B.default.weight: torch.Size([768, 24]), mean=0.000000, std=0.000000\n",
            "  base_model.model.qformer.encoder.layer.0.attention.attention.key.lora_A.default.weight: torch.Size([24, 768]), mean=-0.000052, std=0.020939\n",
            "  base_model.model.qformer.encoder.layer.0.attention.attention.key.lora_B.default.weight: torch.Size([768, 24]), mean=0.000000, std=0.000000\n",
            "  base_model.model.qformer.encoder.layer.0.attention.attention.value.lora_A.default.weight: torch.Size([24, 768]), mean=0.000314, std=0.020810\n",
            "  ... and 235 more LoRA parameters\n",
            "\n",
            "Q-Former Analysis:\n",
            "  Total Q-Former parameters: 192,922,368\n",
            "  Q-Former LoRA parameters: 7,262,208\n",
            "✅ Q-Former LoRA is correctly configured!\n",
            "============================================================\n",
            "\n",
            "🚀 Starting LoRA training...\n",
            "============================================================\n",
            "\n",
            "--- Epoch 1/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1/8:   0%|          | 0/138 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:3951: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n",
            "  warnings.warn(\n",
            "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
            "Epoch 1/8: 100%|██████████| 138/138 [04:55<00:00,  2.14s/it, Loss=1.7224, Avg=1.8852, LR=2.8e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 1 completed in 295.42s\n",
            "📊 Average training loss: 1.8852\n",
            "🔢 Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Validation loss: 1.5452\n",
            "🔢 Processed 35/35 valid validation batches\n",
            "Epoch 1: Train=1.8852, Val=1.5452, Time=295.4s\n",
            "📊 Epoch 1 history saved\n",
            "\n",
            "--- Epoch 2/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/8: 100%|██████████| 138/138 [04:54<00:00,  2.14s/it, Loss=1.6797, Avg=1.6454, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 2 completed in 294.67s\n",
            "📊 Average training loss: 1.6454\n",
            "🔢 Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Validation loss: 1.5053\n",
            "🔢 Processed 35/35 valid validation batches\n",
            "Epoch 2: Train=1.6454, Val=1.5053, Time=294.7s\n",
            "📊 Epoch 2 history saved\n",
            "Model saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_2.pth\n",
            "Checkpoint saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_2.pth\n",
            "💾 Checkpoint saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_2.pth\n",
            "\n",
            "--- Epoch 3/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/8: 100%|██████████| 138/138 [04:54<00:00,  2.13s/it, Loss=1.3979, Avg=1.6001, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 3 completed in 294.47s\n",
            "📊 Average training loss: 1.6001\n",
            "🔢 Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Validation loss: 1.4704\n",
            "🔢 Processed 35/35 valid validation batches\n",
            "Epoch 3: Train=1.6001, Val=1.4704, Time=294.5s\n",
            "📊 Epoch 3 history saved\n",
            "\n",
            "--- Epoch 4/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/8: 100%|██████████| 138/138 [04:54<00:00,  2.14s/it, Loss=1.5805, Avg=1.5805, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 4 completed in 294.77s\n",
            "📊 Average training loss: 1.5805\n",
            "🔢 Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Validation loss: 1.4425\n",
            "🔢 Processed 35/35 valid validation batches\n",
            "Epoch 4: Train=1.5805, Val=1.4425, Time=294.8s\n",
            "📊 Epoch 4 history saved\n",
            "Model saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_4.pth\n",
            "Checkpoint saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_4.pth\n",
            "💾 Checkpoint saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_4.pth\n",
            "\n",
            "--- Epoch 5/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/8: 100%|██████████| 138/138 [04:54<00:00,  2.14s/it, Loss=1.4594, Avg=1.5574, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 5 completed in 294.78s\n",
            "📊 Average training loss: 1.5574\n",
            "🔢 Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Validation loss: 1.4378\n",
            "🔢 Processed 35/35 valid validation batches\n",
            "Epoch 5: Train=1.5574, Val=1.4378, Time=294.8s\n",
            "📊 Epoch 5 history saved\n",
            "\n",
            "--- Epoch 6/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/8: 100%|██████████| 138/138 [04:54<00:00,  2.13s/it, Loss=1.4108, Avg=1.5413, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 6 completed in 294.20s\n",
            "📊 Average training loss: 1.5413\n",
            "🔢 Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Validation loss: 1.4305\n",
            "🔢 Processed 35/35 valid validation batches\n",
            "Epoch 6: Train=1.5413, Val=1.4305, Time=294.2s\n",
            "📊 Epoch 6 history saved\n",
            "Model saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_6.pth\n",
            "Checkpoint saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_6.pth\n",
            "💾 Checkpoint saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_6.pth\n",
            "\n",
            "--- Epoch 7/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/8: 100%|██████████| 138/138 [04:54<00:00,  2.13s/it, Loss=1.6078, Avg=1.5282, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 7 completed in 294.62s\n",
            "📊 Average training loss: 1.5282\n",
            "🔢 Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Validation loss: 1.4175\n",
            "🔢 Processed 35/35 valid validation batches\n",
            "Epoch 7: Train=1.5282, Val=1.4175, Time=294.6s\n",
            "📊 Epoch 7 history saved\n",
            "\n",
            "--- Epoch 8/8 ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/8: 100%|██████████| 138/138 [04:54<00:00,  2.13s/it, Loss=1.7005, Avg=1.5184, LR=3.0e-04]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Epoch 8 completed in 294.45s\n",
            "📊 Average training loss: 1.5184\n",
            "🔢 Processed 138/138 valid batches\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📈 Validation loss: 1.4190\n",
            "🔢 Processed 35/35 valid validation batches\n",
            "Epoch 8: Train=1.5184, Val=1.4190, Time=294.5s\n",
            "📊 Epoch 8 history saved\n",
            "Model saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_8.pth\n",
            "Checkpoint saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_8.pth\n",
            "💾 Checkpoint saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_8.pth\n",
            "\n",
            "============================================================\n",
            "🎉 Training Completed!\n",
            "============================================================\n",
            "📊 Detailed training summary saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/training_summary_detailed.json\n",
            "📈 Training curves saved to checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/training_curves.png\n",
            "📊 Detailed training summary with plots saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/training_summary_detailed.json\n",
            "📄 Basic training summary saved: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/training_summary.json\n",
            "💾 Latest checkpoint: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_8.pth\n",
            "📁 All files saved to: checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058\n",
            "\n",
            "✅ All done!\n",
            "✅ Configuration 1 completed successfully!\n",
            "\n",
            "============================================================\n",
            "🎉 Training Pipeline Completed!\n",
            "============================================================\n",
            "✅ Successful: 1\n",
            "❌ Failed: 0\n",
            "\n",
            "📊 Successful Runs:\n",
            "  - grid_search_v7_Higher_Lora_Wider_Batch.yml → checkpoints/grid_search_v7_Higher_Lora_Wider_Batch_20250724_221058/checkpoint_epoch_8.pth\n"
          ]
        }
      ]
    }
  ]
}