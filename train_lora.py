#!/usr/bin/env python3
"""
Clean LoRA Training Script for InstructBLIP on RSICap
Supports YAML configuration files for flexible training
"""

import sys
import os
import json
import yaml
from datetime import datetime
sys.path.insert(0, os.path.join(os.path.dirname(__file__), 'module'))

from config import Config
from data.rsicap_dataset import load_rsicap_data, RSICapDataset, collate_fn
from torch.utils.data import DataLoader
from models.lora_model import LoRAInstructBLIP
from training.trainer import LoRATrainer
import torch
import gc

# å¼ºåˆ¶æ¸…ç†
torch.cuda.empty_cache()
gc.collect()

# ä¸­å›½é•œåƒæ”¯æŒ
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'

# ============================================================================
# CONFIGURATION FILES TO RUN
# ============================================================================
# Define which config files to run (can be single or multiple)
CONFIG_FILES = [
    "configs/baseline_lora_instructblip.yml",
    # "configs/high_lr_experiment.yml",  # Add more configs here
    # "configs/large_batch_experiment.yml",
]

# ============================================================================
# YAML CONFIG LOADER
# ============================================================================
def load_yaml_config(config_path):
    """Load configuration from YAML file"""
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Config file not found: {config_path}")

    with open(config_path, 'r', encoding='utf-8') as f:
        yaml_config = yaml.safe_load(f)

    print(f"ğŸ“‹ Loaded config: {yaml_config.get('name', 'unnamed')}")
    if 'description' in yaml_config:
        print(f"ğŸ“ Description: {yaml_config['description']}")

    return yaml_config

def train_single_config(config_path):
    """Train with a single YAML configuration"""

    # Load YAML configuration
    yaml_config = load_yaml_config(config_path)

    print("="*60)
    print("ğŸš€ LoRA Training - InstructBLIP on RSICap")
    print(f"ğŸ“‹ Config: {yaml_config.get('name', 'unnamed')}")
    print("="*60)

    # Create config object
    config = Config()

    # Apply YAML config (skip metadata fields)
    metadata_fields = {'name', 'description'}
    for key, value in yaml_config.items():
        if key not in metadata_fields:
            setattr(config, key, value)

    # Create output directory using config name
    config_name = yaml_config.get('name', 'unnamed_config')
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    config.save_dir = f"checkpoints/{config_name}_{timestamp}"
    os.makedirs(config.save_dir, exist_ok=True)
    
    # æ•°æ®è·¯å¾„å·²åœ¨ config.py ä¸­æ­£ç¡®è®¾ç½®

    # æ˜¾ç¤ºé…ç½®
    print(f"ğŸ“‹ Training Configuration:")
    print(f"  LoRA rank (r): {config.lora_r}")
    print(f"  LoRA alpha: {config.lora_alpha}")
    print(f"  Learning rate: {config.learning_rate}")
    print(f"  Epochs: {config.num_epochs}")
    print(f"  Batch size: {config.batch_size}")
    print(f"  Max samples: {config.max_samples}")
    print(f"  Save dir: {config.save_dir}")
    print()

    # åŠ è½½ç»„ä»¶
    print("Loading LoRA model...")
    model = LoRAInstructBLIP(config)
    print("âœ… Model loaded successfully!")

    print("Loading dataset...")
    train_loader, val_loader, processor = load_rsicap_data(config)
    print("âœ… Dataset loaded successfully!")

    # é™åˆ¶æ•°æ®é‡
    if config.max_samples:
        print(f"ğŸ”¢ Limiting training to {config.max_samples} samples")
        limited_train_data = list(train_loader.dataset.data)[:config.max_samples]
        limited_train_dataset = RSICapDataset(
            limited_train_data,
            train_loader.dataset.images_dir,
            train_loader.dataset.processor,
            'train'
        )
        train_loader = DataLoader(
            limited_train_dataset,
            batch_size=config.batch_size,
            shuffle=True,
            num_workers=0,
            pin_memory=True,
            collate_fn=collate_fn
        )
        print(f"âœ… Limited to {len(train_loader)} batches per epoch")

    # åˆ›å»ºè®­ç»ƒå™¨
    print("Creating trainer...")
    trainer = LoRATrainer(
        model=model,
        train_loader=train_loader,
        val_loader=val_loader,
        config=config
    )
    print("âœ… Trainer created successfully!")

    # éªŒè¯ LoRA é…ç½®
    model.verify_lora_training()

    # å¼€å§‹è®­ç»ƒ
    print("\nğŸš€ Starting LoRA training...")
    print("="*60)

    latest_checkpoint_path = None

    for epoch in range(config.num_epochs):
        print(f"\n--- Epoch {epoch + 1}/{config.num_epochs} ---")

        # è®­ç»ƒ
        train_loss, epoch_time = trainer.train_epoch(epoch)

        # éªŒè¯
        val_loss = trainer.validate(epoch)

        print(f"Epoch {epoch + 1}: Train={train_loss:.4f}, Val={val_loss:.4f}, Time={epoch_time:.1f}s")

        # ä¿å­˜æ¯ä¸ªepochçš„å†å²è®°å½•
        epoch_summary = {
            "epoch": epoch + 1,
            "train_loss": train_loss,
            "val_loss": val_loss,
            "epoch_time": epoch_time,
            "learning_rate": trainer.optimizer.param_groups[0]['lr'] if hasattr(trainer, 'optimizer') else None,
            "timestamp": datetime.now().isoformat()
        }

        # ä¿å­˜å•ä¸ªepochæ€»ç»“
        epoch_file = os.path.join(config.save_dir, f"epoch_{epoch+1}_summary.json")
        with open(epoch_file, 'w', encoding='utf-8') as f:
            json.dump(epoch_summary, f, ensure_ascii=False, indent=2)

        # ä¿å­˜ç´¯ç§¯å†å²
        history_file = os.path.join(config.save_dir, "training_history.json")
        if os.path.exists(history_file):
            with open(history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)
        else:
            history = {"epochs": []}

        history["epochs"].append(epoch_summary)
        history["config"] = yaml_config
        history["last_updated"] = datetime.now().isoformat()

        with open(history_file, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)

        print(f"ğŸ“Š Epoch {epoch + 1} history saved")

        # ä¿å­˜æ£€æŸ¥ç‚¹
        if (epoch + 1) % 2 == 0 or epoch == config.num_epochs - 1:
            latest_checkpoint_path = os.path.join(config.save_dir, f"checkpoint_epoch_{epoch+1}.pth")
            trainer.save_checkpoint(latest_checkpoint_path, epoch, train_loss, val_loss)
            print(f"ğŸ’¾ Checkpoint saved: {latest_checkpoint_path}")

    # ä¿å­˜è®­ç»ƒæ€»ç»“å’Œç”Ÿæˆå¯è§†åŒ–
    print("\n" + "="*60)
    print("ğŸ‰ Training Completed!")
    print("="*60)

    # è°ƒç”¨trainerçš„è¯¦ç»†ä¿å­˜åŠŸèƒ½ï¼ˆåŒ…å«å¯è§†åŒ–ï¼‰
    if hasattr(trainer, 'save_training_summary'):
        detailed_summary_path = trainer.save_training_summary()
        print(f"ğŸ“Š Detailed training summary with plots saved: {detailed_summary_path}")
    else:
        # å¦‚æœtraineræ²¡æœ‰è¿™ä¸ªæ–¹æ³•ï¼Œè°ƒç”¨plot_losses
        if hasattr(trainer, 'plot_losses'):
            trainer.plot_losses()
            print(f"ğŸ“ˆ Training curves saved to: {config.save_dir}/training_curves.png")

    # ä¿å­˜åŸºæœ¬æ€»ç»“
    summary = {
        "training_completed": datetime.now().isoformat(),
        "config": yaml_config,
        "final_losses": {
            "train_loss": trainer.train_losses[-1] if trainer.train_losses else None,
            "val_loss": trainer.val_losses[-1] if trainer.val_losses else None
        },
        "best_val_loss": min(trainer.val_losses) if trainer.val_losses else None,
        "total_epochs": len(trainer.train_losses),
        "total_training_time": sum(trainer.epoch_times) if hasattr(trainer, 'epoch_times') else None,
        "checkpoints_dir": config.save_dir
    }

    summary_path = os.path.join(config.save_dir, "training_summary.json")
    with open(summary_path, 'w', encoding='utf-8') as f:
        json.dump(summary, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“„ Basic training summary saved: {summary_path}")
    print(f"ğŸ’¾ Latest checkpoint: {latest_checkpoint_path}")
    print(f"ğŸ“ All files saved to: {config.save_dir}")
    print("\nâœ… All done!")
    return latest_checkpoint_path

def main():
    """Main function to run training with multiple configurations"""

    print("ğŸš€ Starting LoRA Training Pipeline")
    print(f"ğŸ“ Found {len(CONFIG_FILES)} configuration(s) to run")
    print("="*60)

    results = []

    for i, config_path in enumerate(CONFIG_FILES, 1):
        print(f"\nğŸ”„ Running configuration {i}/{len(CONFIG_FILES)}: {config_path}")

        try:
            checkpoint_path = train_single_config(config_path)
            results.append({
                "config_path": config_path,
                "status": "success",
                "checkpoint": checkpoint_path
            })
            print(f"âœ… Configuration {i} completed successfully!")

        except Exception as e:
            print(f"âŒ Configuration {i} failed: {e}")
            results.append({
                "config_path": config_path,
                "status": "failed",
                "error": str(e)
            })

    # Print final summary
    print("\n" + "="*60)
    print("ğŸ‰ Training Pipeline Completed!")
    print("="*60)

    successful = [r for r in results if r["status"] == "success"]
    failed = [r for r in results if r["status"] == "failed"]

    print(f"âœ… Successful: {len(successful)}")
    print(f"âŒ Failed: {len(failed)}")

    if successful:
        print("\nğŸ“Š Successful Runs:")
        for result in successful:
            config_name = os.path.basename(result["config_path"])
            print(f"  - {config_name} â†’ {result['checkpoint']}")

    if failed:
        print("\nğŸ’¥ Failed Runs:")
        for result in failed:
            config_name = os.path.basename(result["config_path"])
            print(f"  - {config_name}: {result['error']}")

if __name__ == "__main__":
    main()
